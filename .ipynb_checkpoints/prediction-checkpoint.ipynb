{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/usr/local/lib/python2.7/site-packages')\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.core import Activation, Dropout, Flatten, Dense, Lambda\n",
    "from keras.layers import ELU\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "\n",
    "N_img_height = 66\n",
    "N_img_width = 220\n",
    "N_img_channels = 3\n",
    "def nvidia_model():\n",
    "    inputShape = (N_img_height, N_img_width, N_img_channels)\n",
    "\n",
    "    model = Sequential()\n",
    "    # normalization    \n",
    "    # perform custom normalization before lambda layer in network\n",
    "    model.add(Lambda(lambda x: x/ 127.5 - 1, input_shape = inputShape))\n",
    "\n",
    "    model.add(Convolution2D(24, (5, 5), \n",
    "                            strides=(2,2), \n",
    "                            padding = 'valid',\n",
    "                            kernel_initializer = 'he_normal',\n",
    "                            name = 'conv1'))\n",
    "    \n",
    "    \n",
    "    model.add(ELU())    \n",
    "    model.add(Convolution2D(36, (5, 5), \n",
    "                            strides=(2,2), \n",
    "                            padding = 'valid',\n",
    "                            kernel_initializer = 'he_normal',\n",
    "                            name = 'conv2'))\n",
    "    \n",
    "    model.add(ELU())    \n",
    "    model.add(Convolution2D(48, (5, 5), \n",
    "                            strides=(2,2), \n",
    "                            padding = 'valid',\n",
    "                            kernel_initializer = 'he_normal',\n",
    "                            name = 'conv3'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(64, (3, 3), \n",
    "                            strides = (1,1), \n",
    "                            padding = 'valid',\n",
    "                            kernel_initializer = 'he_normal',\n",
    "                            name = 'conv4'))\n",
    "    \n",
    "    model.add(ELU())              \n",
    "    model.add(Convolution2D(64, (3, 3), \n",
    "                            strides= (1,1), \n",
    "                            padding = 'valid',\n",
    "                            kernel_initializer = 'he_normal',\n",
    "                            name = 'conv5'))\n",
    "              \n",
    "              \n",
    "    model.add(Flatten(name = 'flatten'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(100, kernel_initializer = 'he_normal', name = 'fc1'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(50, kernel_initializer = 'he_normal', name = 'fc2'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(10, kernel_initializer = 'he_normal', name = 'fc3'))\n",
    "    model.add(ELU())\n",
    "    \n",
    "    # do not put activation at the end because we want to exact output, not a class identifier\n",
    "    model.add(Dense(1, name = 'output', kernel_initializer = 'he_normal'))\n",
    "    \n",
    "    adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(optimizer = adam, loss = 'mse')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nvidia_model()\n",
    "model.load_weights('model-weights-Vtest3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def opticalFlowOverlay(image_current, image_next):\n",
    "    \"\"\"\n",
    "    input: image_currentdef preprocess_image_from_path(image_path, scale_factor=0.5, bright_factor=1):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = change_brightness(img, bright_factor)\n",
    "    img = crop_image(img, scale_factor)\n",
    "    return img, image_next (RGB images)\n",
    "    output: mask\n",
    "    \"\"\"\n",
    "    feature_params = dict( maxCorners = 500,\n",
    "                       qualityLevel = 0.1,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 5 )\n",
    "    lk_params = dict( winSize  = (15, 15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "    \n",
    "    image_current_saved = np.copy(image_current)\n",
    "    image_next_saved = np.copy(image_next)\n",
    "    \n",
    "    image_current = cv2.cvtColor(image_current, cv2.COLOR_RGB2GRAY)\n",
    "    image_next = cv2.cvtColor(image_next, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Finds edges in an image using the [Canny86] algorithm.\n",
    "    p0 = cv2.goodFeaturesToTrack(image_current, mask = None, **feature_params)\n",
    "\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(image_current, image_next, p0, None, **lk_params)\n",
    "\n",
    "\n",
    "    color = np.random.randint(0, 255, (100, 3))\n",
    "\n",
    "    mask = np.zeros_like(image_current)\n",
    "\n",
    "    # Select good points\n",
    "    good_new = p1[st == 1]\n",
    "    good_old = p0[st == 1]\n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel() # flatten\n",
    "        c, d = old.ravel()\n",
    "        mask = cv2.arrowedLine(mask, (a,b), (c, d), color[i%100].tolist(), 1, 8)\n",
    "        \n",
    "        image_next = cv2.circle(image_next_saved, (a, b), 1, color[i%100].tolist(), -1)\n",
    "        image_next_fg = cv2.bitwise_and(image_next, image_next, mask = mask)\n",
    "        \n",
    "    dst = cv2.add(image_next, image_next_fg)\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_image(image, scale):\n",
    "    \"\"\"\n",
    "    preprocesses the image\n",
    "    \n",
    "    input: image (480 (y), 640 (x), 3) RGB\n",
    "    output: image (shape is (66, 220, 3) as RGB)\n",
    "    \n",
    "    This stuff is performed on my validation data and my training data\n",
    "    Process: \n",
    "             1) Cropping out black spots\n",
    "             3) resize to (66, 220, 3) if not done so already from perspective transform\n",
    "    \"\"\"\n",
    "    # Crop out sky (top 130px) and the hood of the car (bottom 270px) \n",
    "    image_cropped = image[130:370,:] # -> (240, 640, 3)\n",
    "    \n",
    "    height = int(240*scale)\n",
    "    width = int(640*scale)\n",
    "    image = cv2.resize(image_cropped, (220, 66), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def opticalFlowDense(image_current, image_next):\n",
    "    \"\"\"\n",
    "    input: image_current, image_next (RGB images)\n",
    "    calculates optical flow magnitude and angle and places it into HSV image\n",
    "    * Set the saturation to the saturation value of image_next\n",
    "    * Set the hue to the angles returned from computing the flow params\n",
    "    * set the value to the magnitude returned from computing the flow params\n",
    "    * Convert from HSV to RGB and return RGB image with same size as original image\n",
    "    \"\"\"\n",
    "    gray_current = cv2.cvtColor(image_current, cv2.COLOR_RGB2GRAY)\n",
    "    gray_next = cv2.cvtColor(image_next, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    hsv = np.zeros(image_current.shape)\n",
    "    # set saturation\n",
    "    hsv[:,:,1] = cv2.cvtColor(image_next, cv2.COLOR_RGB2HSV)[:,:,1]\n",
    " \n",
    "    # Flow Parameters\n",
    "    flow_mat = None\n",
    "    image_scale = 0.5\n",
    "    nb_images = 1\n",
    "    win_size = 15\n",
    "    nb_iterations = 2\n",
    "    deg_expansion = 5\n",
    "    STD = 1.3\n",
    "    extra = 0\n",
    "\n",
    "    # obtain dense optical flow paramters\n",
    "    flow = cv2.calcOpticalFlowFarneback(gray_current, gray_next,  \n",
    "                                        flow_mat, \n",
    "                                        image_scale, \n",
    "                                        nb_images, \n",
    "                                        win_size, \n",
    "                                        nb_iterations, \n",
    "                                        deg_expansion, \n",
    "                                        STD, \n",
    "                                        0)\n",
    "                                        \n",
    "        \n",
    "    # convert from cartesian to polar\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])  \n",
    "        \n",
    "    # hue corresponds to direction\n",
    "    hsv[:,:,0] = ang * (180/ np.pi / 2)\n",
    "    \n",
    "    # value corresponds to magnitude\n",
    "    hsv[:,:,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "    \n",
    "    # convert HSV to float32's\n",
    "    hsv = np.asarray(hsv, dtype= np.float32)    \n",
    "\n",
    "    rgb_flow = cv2.cvtColor(hsv,cv2.COLOR_HSV2RGB)\n",
    "\n",
    "    \n",
    "    return rgb_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image_from_path(image_path, scale_factor=0.5, bright_factor=1):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = crop_image(img, scale_factor)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "driving.csv      predict.csv      \u001b[34mtest_frames\u001b[m\u001b[m/     train.txt\r\n",
      "\u001b[34mpredict\u001b[m\u001b[m/         test.mp4         train.mp4        \u001b[34mtraining_frames\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_frames(video_source, speed_data):\n",
    "    \n",
    "    '''\n",
    "    Captures .mp4 video frames to .jpg images and creates a .csv to store the capture information\n",
    "    '''\n",
    "    \n",
    "    num_frames = speed_data.shape[0]\n",
    "    \n",
    "    # create VideoCapture instance\n",
    "    cap = cv2.VideoCapture(video_source)\n",
    "    # set frame count\n",
    "    cap.set(cv2.CAP_PROP_FRAME_COUNT, num_frames)\n",
    "    \n",
    "    with open('./data/predict.csv', 'w') as csvfile:\n",
    "        fieldnames = ['image_path', 'frame', 'speed']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames = fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for idx in xrange(num_frames):\n",
    "            # set frame index\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "            # read the frame\n",
    "            success, image = cap.read()\n",
    "\n",
    "            if success:\n",
    "                image_path = os.path.join('./data/test_frames/', str(idx) + '.jpg')\n",
    "\n",
    "                # save image to IMG folder\n",
    "                cv2.imwrite(image_path, image)\n",
    "\n",
    "                # write row to driving.csv\n",
    "                writer.writerow({'image_path': image_path,\n",
    "                         'frame': idx,\n",
    "                         'speed': speed_data[idx],\n",
    "                        })\n",
    "            else:\n",
    "                print 'Failed to read frame ', idx\n",
    "        \n",
    "        print 'Done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/driving.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>frame</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/training_frames/0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>28.105569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./data/training_frames/1.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>28.105569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./data/training_frames/2.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>28.106527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./data/training_frames/3.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>28.130404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./data/training_frames/4.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>28.109243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>./data/training_frames/5.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>28.088572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>./data/training_frames/6.jpg</td>\n",
       "      <td>6</td>\n",
       "      <td>28.034211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>./data/training_frames/7.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>28.018491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>./data/training_frames/8.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>27.986624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>./data/training_frames/9.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>28.016352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     image_path  frame      speed\n",
       "0  ./data/training_frames/0.jpg      0  28.105569\n",
       "1  ./data/training_frames/1.jpg      1  28.105569\n",
       "2  ./data/training_frames/2.jpg      2  28.106527\n",
       "3  ./data/training_frames/3.jpg      3  28.130404\n",
       "4  ./data/training_frames/4.jpg      4  28.109243\n",
       "5  ./data/training_frames/5.jpg      5  28.088572\n",
       "6  ./data/training_frames/6.jpg      6  28.034211\n",
       "7  ./data/training_frames/7.jpg      7  28.018491\n",
       "8  ./data/training_frames/8.jpg      8  27.986624\n",
       "9  ./data/training_frames/9.jpg      9  28.016352"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20400"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-6d4fc376f45f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# convert back to BGR for writing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_RGB2BGR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(len(data)-1):\n",
    "    y1 = data.iloc[i]['speed']\n",
    "    y2 = data.iloc[i+1]['speed']\n",
    "    \n",
    "    x1 = preprocess_image_from_path(data.iloc[i]['image_path'])\n",
    "    x2 = preprocess_image_from_path(data.iloc[i+1]['image_path'])\n",
    "    \n",
    "    img1 = cv2.cvtColor(cv2.imread(data.iloc[i]['image_path']), cv2.COLOR_BGR2RGB)\n",
    "    img2 = cv2.cvtColor(cv2.imread(data.iloc[i+1]['image_path']), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "    rgb_diff = opticalFlowDense(x1, x2)\n",
    "    rgb_diff = rgb_diff.reshape(1, rgb_diff.shape[0], rgb_diff.shape[1], rgb_diff.shape[2])\n",
    "    avg_speed = np.array([[np.mean([y1,y2])]])\n",
    "    \n",
    "    prediction = model.predict(rgb_diff)\n",
    "    error = abs(prediction - y2)\n",
    "    truth = y2\n",
    "    \n",
    "    predict_path = os.path.join('./data/predict/', str(i) + '.jpg')\n",
    "    \n",
    "    dst = np.copy(img2)\n",
    "    \n",
    "    dst = opticalFlowOverlay(img1, img2) # This is a sparse optical flow overlay\n",
    "    \n",
    "    # to write new image via openCV\n",
    "    offset = 50\n",
    "    FONT_SIZE = 1\n",
    "    THICKNESS = 1\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(dst,'pred: ' + str(prediction[0][0])[:5],(10,offset), font, FONT_SIZE,(150,255,235), THICKNESS,cv2.LINE_AA)\n",
    "    cv2.putText(dst,'truth: ' + str(y2)[:5],(10,offset * 1.7), font, FONT_SIZE,(200,255,170), THICKNESS,cv2.LINE_AA)\n",
    "    cv2.putText(dst, 'error: ' + str(error[0][0])[:5], (10, offset*3.4),font, FONT_SIZE, (255, 120, 80), THICKNESS, cv2.LINE_AA)\n",
    "    \n",
    "    # convert back to BGR for writing\n",
    "    dst = cv2.cvtColor(dst, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(predict_path, dst)\n",
    "    \n",
    "print('done!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
